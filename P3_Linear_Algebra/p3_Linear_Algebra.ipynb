{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性代数：机器学习背后的优化原理\n",
    "\n",
    "        \n",
    "线性代数作为数学的一个分支，广泛应用于科学和工程中，掌握好线性代数对于理解和从事机器学习算法相关工作是很有必要的，尤其对于深度学习算法而言。因此，这个项目会从浅入深更好的帮助你学习与积累一些跟人工智能强相关的线性代数的知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "\n",
    "我们将讲解常用的线性代数知识，而学员需使用numpy来实现这些知识点（当然也可以自己写算法实现），还需要使用matplotlib完成规定图像习题，当然，本项目用到的python代码(或numpy的使用)课程中并未完全教授，所以需要学员对相应操作进行学习与查询，这在我们往后的人工智能学习之旅中是必不可少的一个技能，请大家珍惜此项目的练习机会。\n",
    "\n",
    "当然，这里提供官方的[numpy Quickstart](https://docs.scipy.org/doc/numpy/user/quickstart.html#)来帮助你更好的完成项目。\n",
    "\n",
    "本项目还需要使用LaTeX公式，以下两个链接供学习与使用：\n",
    "\n",
    "[Latex cheatsheet](https://www.authorea.com/users/77723/articles/110898-how-to-write-mathematical-equations-expressions-and-symbols-with-latex-a-cheatsheet)\n",
    "\n",
    "[aTeX Cookbook](http://www.personal.ceu.hu/tex/cookbook.html#inline)\n",
    "\n",
    "首先，导入你所需的软件包。一般我们建议在工程开头导入**所有**需要的软件包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: import相关库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、标量，向量，矩阵，张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**首先，让我们回顾下基本的定义：**\n",
    "\n",
    "- 标量（scalar）：形式而言，一个标量是一个单独的数，常用斜体的小写变量名称来表示。_v_\n",
    "\n",
    "- 向量（vector）：形式而言，一个向量是一列有序数，常用粗体的小写变量名称表示**v**，或者上面标记剪头$\\vec{v}$ \n",
    "\n",
    "- 矩阵（matrix）：形式而言，一个矩阵是一个二维数组，常用大写变量名称表示A，表示内部的元素则会使用$A_{i,j}$\n",
    "\n",
    "- 张量（tensor）：形式而言，一个张量是一个多维数组，常用粗体的大写字母变量名称表示**T**，表示内部的元素则会使用$A_{i,j,z}$ 等等\n",
    "\n",
    "用图片直观的显示区别如下\n",
    "<img src=\"images/diff.png\" width=\"500\">\n",
    "\n",
    "**接下来让我们回顾下基本的运算：**\n",
    "\n",
    "- 加法\n",
    "<img src=\"images/add.png\" width=\"500\">\n",
    "\n",
    "- 标量乘法\n",
    "<img src=\"images/scmu.png\" width=\"400\">\n",
    "\n",
    "- 转置\n",
    "<img src=\"images/trans.png\" width=\"370\">\n",
    "\n",
    "- 矩阵向量乘法（内积，人工智能中常见的拼写：matrix product 或者 dot product） \n",
    "<img src=\"images/mul.png\" width=\"570\">\n",
    "\n",
    "**线性方程组：**\n",
    "\n",
    "由矩阵乘法也演变出了我们最常见的线性方程组，已知矩阵与未知向量的乘积，等于另一个已知向量，通过此方程组可求解那个未知向量，一般写为x，具体如下表示。\n",
    "等式左侧可以这么来理解：\n",
    "<img src=\"images/axb.png\" width=\"400\">\n",
    "列为具体的矩阵来看：\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    A_{1,1} & A_{1,2} & \\cdots & A_{1,n} \\\\\\\\\n",
    "    A_{2,1} & A_{2,2} & \\cdots & A_{2,n} \\\\\\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots \\\\\\\\\n",
    "    A_{m,1} & A_{m,2} & \\cdots & A_{m,n}\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "    x_1 \\\\\\\\\n",
    "    x_2 \\\\\\\\\n",
    "    \\cdots \\\\\\\\\n",
    "    x_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    b_1 \\\\\\\\\n",
    "    b_2 \\\\\\\\\n",
    "    \\cdots \\\\\\\\\n",
    "    b_m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "或者更简单的表示为\n",
    "\n",
    "$$Ax=b$$\n",
    "\n",
    "既然有未知数，那么自然需要求解未知数，而我们的未知数需要满足所有方程，也不是一直都有解的，下面来列我们二维矩阵所组成的方程解的情况,若两条线平行不存在焦点，那么说明没有一个$x_1$, $x_2$同时满足两个方程，则此方程组无解，同理，若相交，则有一个解，若完全相等，则有无穷个解。\n",
    "<img src=\"images/axbsolu.png\" width=\"570\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1、基本运算并绘图\n",
    "例题 $\\vec{v}$ + $\\vec{w}$\n",
    "\n",
    "$\\hspace{1cm}\\vec{v} = \\begin{bmatrix} 1\\\\ 1\\end{bmatrix}$\n",
    "\n",
    "\n",
    "$\\hspace{1cm}\\vec{w} = \\begin{bmatrix} -2\\\\ 2\\end{bmatrix}$\n",
    "\n",
    "结果需要先使用numpy计算向量运算结果，并用LaTeX公式表示：\n",
    "\n",
    "$\\hspace{1cm}\\vec{v}+\\vec{w} = \\begin{bmatrix} -1\\\\ 3\\end{bmatrix}$\n",
    "\n",
    "并使用matlibplot绘制出(图表颜色样式不要求)\n",
    "\n",
    "<img src=\"images/add_e.png\" width=\"300\">\n",
    "\n",
    "#### 1.1.1\n",
    "**根据上面例题展示，计算并绘制  $2\\vec{v}$ - $\\vec{w}$  的结果**\n",
    "\n",
    "$\\hspace{1cm}\\vec{v} = \\begin{bmatrix} 4\\\\ 1\\end{bmatrix}$\n",
    "\n",
    "\n",
    "$\\hspace{1cm}\\vec{w} = \\begin{bmatrix} -1\\\\ 2\\end{bmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.1.1 TODO："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例题，方程组求解：\n",
    "$$\n",
    "\\begin{cases}\n",
    "y = 2x + 1\\\\\\\\\n",
    "y = 6x - 2\n",
    "\\end{cases}\n",
    "$$\n",
    "用matplotlib绘制图表（图表样式不要求）\n",
    "<img src=\"images/2equ_solu.png\" width=\"300\">\n",
    "由上可知此方程组有且仅有一个解\n",
    "\n",
    "需使用numpy（或自写算法）计算该解的结果,并用LaTeX公式表示出来(结果可以用小数或者分数展示)\n",
    "$$\n",
    "\\begin{cases}\n",
    "x = \\frac{3}{4} \\\\\\\\\n",
    "y = \\frac{5}{2}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "#### 1.1.2 \n",
    "**根据上面例题展示，绘制方程组，说明是否有解是否为唯一解，若有解需计算出方程组的解**\n",
    "$$\n",
    "\\begin{cases}\n",
    "y = 2x + 1\\\\\\\\\n",
    "y = \\frac{1}{10}x+6\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.1.2 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2、说明题\n",
    "#### 1.2.1\n",
    "**使用numpy（或自写算法）说明$(AB)^{\\text{T}} = B^\\text{T}A^\\text{T}$**\n",
    "\n",
    "**其中**\n",
    "$$\n",
    "A=\\begin{bmatrix}\n",
    "    21 & 7 \\\\\\\\\n",
    "    15 & 42 \\\\\\\\\n",
    "    9 & 6\n",
    "\\end{bmatrix}, \n",
    "B=\\begin{bmatrix}\n",
    "    4 \\\\\\\\\n",
    "    33\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.2.1 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2\n",
    "**使用numpy（或自写算法）说明  $A ( B + C ) = AB + BC$ **\n",
    "\n",
    "**其中**\n",
    "$$\n",
    "A=\\begin{bmatrix}\n",
    "    9 & 3 \\\\\\\\\n",
    "    8 & 4 \\\\\\\\\n",
    "    7 & 6\n",
    "\\end{bmatrix}, \n",
    "B=\\begin{bmatrix}\n",
    "    5 \\\\\\\\\n",
    "    2\n",
    "\\end{bmatrix}, \n",
    "C=\\begin{bmatrix}\n",
    "    5 \\\\\\\\\n",
    "    7\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.2.2 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、特殊矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 单位矩阵\n",
    "\n",
    "如果选取任意一个向量和某矩阵相乘，该向量都不会改变，我们将这种保持n维向量不变的矩阵记为单位矩阵$I_n$\n",
    "\n",
    "- 逆矩阵\n",
    "\n",
    "如果存在一个矩阵，使$A^{-1} A = I_n$，那么$A^{-1}$就是A的逆矩阵。\n",
    "\n",
    "- 对角矩阵\n",
    "\n",
    "如果一个矩阵只有主对角线上还有非零元素，其他位置都是零，这个矩阵就是对角矩阵\n",
    "\n",
    "- 对称矩阵\n",
    "\n",
    "如果一个矩阵的转置是和它自己相等的矩阵，即$A=A^{T}$，那么这个矩阵就是对称矩阵\n",
    "\n",
    "- 正交矩阵\n",
    "\n",
    "行向量和列向量是分别标准正交(90度)的方阵，即$A^{T}A = AA^{T} = I_n$，又即$A^{-1} = A^{T}$，那么这种方阵就是正交矩阵\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2.1、证明题\n",
    "\n",
    "通过LaTeX公式，结合上面所述概念，假设$A^{-1}$存在的情况下，证明$Ax=b$的解$x={A}^{-1}{b}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2、 计算题\n",
    "\n",
    "#### 2.2.1\n",
    "\n",
    "通过numpy计算，再次验证2.1证明题\n",
    "$$\n",
    "\\begin{cases}\n",
    "y = 2x + 1\\\\\\\\\n",
    "y = \\frac{1}{10}x+6\n",
    "\\end{cases}\n",
    "$$\n",
    "并用LaTeX公式写出$A^{-1}$是多少（小数分数皆可）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.2.1 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2\n",
    "\n",
    "1、请用numpy（或自写算法）实现一个对角矩阵，矩阵的斜边由3至8（含8）组成\n",
    "\n",
    "2、计算小1生成的对角矩阵与向量$[6,7,1,2,5,9]^{T}$的乘积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.2.2 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、迹运算\n",
    "迹运算返回的是矩阵对角元素的和，如图所示\n",
    "<img src=\"images/matrix.png\" width=\"360\">\n",
    "写成数学公式为：\n",
    "$$ \\large Tr(A) = \\sum_{i}A_{i,i}$$\n",
    "\n",
    "**说明题：**\n",
    "\n",
    "使用numpy验证\n",
    "$$\n",
    "\\large Tr(ABC) = Tr(CAB) = Tr(BCA)\n",
    "$$\n",
    "其中\n",
    "$$\n",
    "A=\n",
    "\\begin{bmatrix}\n",
    "    7 & 6 \\\\\\\\\n",
    "    29 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "B=\n",
    "\\begin{bmatrix}\n",
    "    2 & -8 \\\\\\\\\n",
    "    9 & 10\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C=\n",
    "\\begin{bmatrix}\n",
    "    2 & 17 \\\\\\\\\n",
    "    1 & 5\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4、衡量向量以及矩阵的大小：范数与条件数\n",
    "\n",
    "### 范数的定义\n",
    "\n",
    "在线性代数，函数分析等数学分支中，范数（Norm）是一个函数，其赋予某个向量空间（或矩阵）中的每个向量以长度或大小。对于零向量，另其长度为零。直观的说，向量或矩阵的范数越大，则我们可以说这个向量或矩阵也就越大。有时范数有很多更为常见的叫法，如绝对值其实便是一维向量空间中实数或复数的范数，范数的一般化定义：设$p\\ge 1$，p-norm用以下来表示\n",
    "\n",
    "\n",
    "$$ \\large {\\Vert x \\Vert}_{p} =  \\lgroup {\\sum_{i}{\\vert x_i \\vert}^p }\\rgroup ^{\\frac{1}{p}}$$\n",
    "\n",
    "此处，当p=1时，我们称之为taxicab Norm，也叫Manhattan Norm，中文是曼哈顿范数。其来源是曼哈顿的出租车司机在四四方方的曼哈顿街道中从一点到另一点所需要走过的距离。也即我们所要讨论的L1范数。其表示某个向量中所有元素绝对值的和。 而当p=2时，则是我们最为常见的Euclidean norm。也称为Euclidean distance，中文叫欧几里得范数，也即我们要讨论的L2范数，他也经常被用来衡量向量的大小。 而当p=0时，严格的说此时p已不算是范数了，但很多人仍然称之为L0范数。 这三个范数有很多非常有意思的特征，尤其是在机器学习中的正则化（Regularization）以及稀疏编码（Sparse Coding）有非常有趣的应用，这个在进阶课程可以做跟深入的了解，那么这里不再讲解L0范数。\n",
    "\n",
    "**L1 范数**\n",
    "$$ \\large {\\Vert x \\Vert}_{1} =  \\lgroup {\\sum_{i}{\\vert x_i \\vert} }\\rgroup $$\n",
    "**L2 范数**\n",
    "$$ \\large {\\Vert x \\Vert}_{2} =  \\lgroup {\\sum_{i}{\\vert x_i \\vert}^2 }\\rgroup ^{\\frac{1}{2}}$$\n",
    "\n",
    "另外这里还存在特例：\n",
    " 当 $ p -> \\infty $ 时，我们称之为 $ L^{\\infty} $范数，也被称为“max范数”，这个范数表示向量中具有最大幅度的元素的绝对值：\n",
    "\n",
    "$$ \\large {\\Vert x \\Vert}^{\\infty} =  \\max_{i}{\\vert x_i \\vert} $$\n",
    "\n",
    "### 4.1、计算向量的范数\n",
    "编写一个函数来计算一下向量的各种范数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 实现这里向量范数计算的函数，要求可以计算p = 0,1,2,3 ... 无穷 情况下的范数\n",
    "\n",
    "\"\"\" 计算向量的范数\n",
    "    参数\n",
    "        x: 向量 numpy数组 或者list数组\n",
    "        p: 范数的阶，int型整数或者None\n",
    "        infty: 是否计算max范数，bool型变量，True的时候表示计算max范数，False的时候计算p范数\n",
    "        \n",
    "    返回\n",
    "        向量的范数，float类型数值\n",
    "        \n",
    "    hint:\n",
    "        1.你需要首先判断infty是True or False, 然后判断p 是否为零\n",
    "        2.注意int类型变量在计算时候需要规整为float类型\n",
    "    \n",
    "\"\"\"\n",
    "def calc_Norm(x, p = 2, infty = False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2、计算矩阵的范数\n",
    "我们也需要衡量矩阵的大小，对于矩阵大小的衡量在很多优化问题中是非常重要的。而在深度学习中，最常见的做法是使用Frobenius 范数(Frobenius norm)，也称作矩阵的F范数，其定义如下：\n",
    "\n",
    "$$ \\large {\\Vert A \\Vert}_{F} =  \\sqrt {\\sum_{i,j}{\\vert A_{i,j} \\vert}^2 } $$\n",
    "\n",
    "我们这里继续来计算一下F范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 实现这里矩阵Frobenius范数计算的函数\n",
    "\n",
    "\"\"\" 计算向量的范数\n",
    "    参数\n",
    "        A: 给定的任意二维矩阵 list或者numpy数组形式\n",
    "        \n",
    "    返回\n",
    "        矩阵的Frobenius范数，float类型数值\n",
    "    \n",
    "\"\"\"\n",
    "def calc_Frobenius_Norm(A):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3、计算矩阵的条件数\n",
    "矩阵的条件数(condition number)是矩阵（或者它所描述的线性系统）的稳定性或者敏感度的度量，我们这里为了简化条件，这里只考虑矩阵是奇异矩阵的时候，如何计算以及理解条件数(condition number):\n",
    "\n",
    "当矩阵A为奇异矩阵的时候，condition number为无限大；当矩阵A非奇异的时候，我们定义condition number如下：\n",
    "\n",
    "$$ \\large \\kappa{(A)} =  {\\Vert A \\Vert}_F {\\Vert A^{-1} \\Vert}_F$$\n",
    "\n",
    "[奇异矩阵，非奇异矩阵](https://zh.wikipedia.org/wiki/%E9%9D%9E%E5%A5%87%E5%BC%82%E6%96%B9%E9%98%B5)\n",
    "\n",
    "计算矩阵的条件数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 计算矩阵的条件数\n",
    "    参数\n",
    "        A: 给定的任意二维矩阵 list或者numpy数组形式\n",
    "        \n",
    "    返回\n",
    "        矩阵的condition number,\n",
    "    \n",
    "\"\"\"\n",
    "def calc_Condition_Number(A):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (选做中选做)4.4、条件数的理解与应用\n",
    "\n",
    "a. 尝试构造两个2*2的非奇异矩阵A和B:\n",
    "\n",
    "$ A = \\begin{bmatrix}\n",
    "     a_{11}   &a_{12} \\\\\n",
    "     a_{21}   &a_{22} \\\\\n",
    "\\end{bmatrix} $ \n",
    "$ B = \\begin{bmatrix}\n",
    "     b_{11}   &b_{12} \\\\\n",
    "     b_{21}   &b_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "要求 condition number(A) < 20.0, condition number(B) > 20000.0\n",
    "\n",
    "b. 根据上面构造的矩阵A,B分别计算线性系统方程组的解$w$:\n",
    "\n",
    "\n",
    "   A $ \\begin{bmatrix}w_{a1}\\\\w_{a2}\\\\ \\end{bmatrix} $ = $ \\begin{bmatrix}y_{a1}\\\\y_{a2}\\\\ \\end{bmatrix} $, \n",
    "    \n",
    "   B $ \\begin{bmatrix}w_{b1}\\\\w_{b2}\\\\ \\end{bmatrix} $ = $ \\begin{bmatrix}y_{b1}\\\\y_{b2}\\\\ \\end{bmatrix} $,\n",
    "   \n",
    "   A $ \\begin{bmatrix}w_{a1}\\\\w_{a2}\\\\ \\end{bmatrix} $ = $ \\begin{bmatrix}{y_{a1} + 0.0001}\\\\{y_{a2} + 0.0001}\\\\ \\end{bmatrix} $, \n",
    "    \n",
    "   B $ \\begin{bmatrix}w_{b1}\\\\w_{b2}\\\\ \\end{bmatrix} $ = $ \\begin{bmatrix}{y_{b1} + 0.0001}\\\\{y_{b2} + 0.0001}\\\\ \\end{bmatrix} $.\n",
    "\n",
    "其中 y需要自己选定合适的值，\n",
    "\n",
    "c. 计算完成之后，比较condition number大小与线性系统稳定性之间的关系，并且给出规律性的总结；\n",
    "\n",
    "d. 考虑更为通用的一种情况，我们计算一个典型的线性回归系统: \n",
    "\n",
    "$$\\large Xw = b$$\n",
    "\n",
    "其闭式解为：$ w=(X^TX)^{−1}X^Tb $ ，如果 $X^TX$可逆\n",
    "\n",
    "当我们需要拟合的数据X满足数据量远远小于特征数目的时候，也就是X矩阵的行数 << X矩阵的列数；\n",
    "\n",
    "Q1:判断$X^TX$矩阵是否是奇异矩阵，也就是该系统是否存在闭式解；\n",
    "\n",
    "Q2:如果不存在闭式解，我们该如何重新构造$X^TX$，使得该闭式解成立，给出你认为的对于该系统的解影响最小的或者是合适的一种闭式解法。\n",
    " \n",
    "Q3:思考Ridge Regression和 L2范数以及condition number之间的联系，可以给出必要的公式化说明。（选做）\n",
    "\n",
    "hint:单位矩阵的condition number值为1，是最为稳定的；如果要使得该系统存在闭式解，那么就必须使得求逆运算是可以进行的，也就是说重新构造的$X^TX$必须是可逆的方阵；重新构造的方式可以是在$X^TX$基础上进行加或者减或者乘除相关矩阵的操作；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、SVD\n",
    "\n",
    "[SVD](https://en.wikipedia.org/wiki/Singular-value_decomposition)是Singular value decomposition的缩写，称为奇异值分解，是分解矩阵的一种方式，会将矩阵分解为奇异向量（singular vector）和奇异值（singular value），分解的意义其实很明确，就是想将一个很大很复杂的矩阵，用更小更简单的几个子矩阵的相乘来表示，这些小矩阵描述的是矩阵的重要的特性。\n",
    "\n",
    "那么SVD具体的数学表达是什么呢？\n",
    "\n",
    "假设有一个矩阵A，我们可以将矩阵A分解为三个矩阵的乘积：\n",
    "$$\\large A = UDV^{T}$$\n",
    "\n",
    "如果A是一个m x n的矩阵，那么U是一个m x m的矩阵，D是一个m x n的矩阵，V是一个n x n的矩阵，这些小矩阵并不是普普通通的矩阵，U和V都定义为正交矩阵，而D定位为对角矩阵。\n",
    "\n",
    "具体计算UDV的算法不是我们这个项目的关键，我们只需使用numpy得出结果即可，下面的习题，将会带你体会SVD的某一应用场景。\n",
    "\n",
    "提示：我们会需要使用[numpy.linalg](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.linalg.html)相关函数。\n",
    "\n",
    "### 5.1、使用numpy去计算任意矩阵的奇异值分解："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 计算任意矩阵的奇异值分解\n",
    "    参数\n",
    "        A: 给定的任意二维矩阵 list或者numpy数组形式 \n",
    "        \n",
    "    返回\n",
    "        使用numpy.linalg相关函数，直接返回分解之后的矩阵U,D,V\n",
    "        （可以尝试一下使用np.shape一下分解出来的U，D，V，会发现维度跟我们上面讲解所描述的不同，\n",
    "        暂时不用管他直接返回np求解出的U，D，V即可）\n",
    "    \n",
    "\"\"\"\n",
    "def calc_svd(A):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (选做) 5.2、利用奇异值分解对矩阵进行降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 利用SVD进行对于矩阵进行降维\n",
    "\n",
    "\"\"\" 利用SVD进行对于矩阵进行降维\n",
    "    参数\n",
    "        A: 给定的任意二维矩阵 list或者numpy数组形式 shape为(m,n)\n",
    "        topk: 降维的维度 (m,n) -> (m,topk)\n",
    "        \n",
    "    返回\n",
    "        降维后的矩阵 (m, topk)\n",
    "    \n",
    "    hint\n",
    "    1. 对角矩阵D存在一个较为明显的特性，就是D的对角线元素是递减的，这些元素实际上是衡量了所分解的矩阵U,V的列向量的重要性\n",
    "    2. 因此我们常说的svd降维就是利用的选取前topk大的对角线矩阵元素进行构造新的降维矩阵\n",
    "    3. U的按照前topk截取的行向量 * topk截取的对角矩阵 即为新的降维后的矩阵\n",
    "    \n",
    "\"\"\"\n",
    "def calc_svd_decompostion(A, topk = 2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (选做) 5.3、利用奇异值分解对矩阵进行降维后重构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 利用SVD进行对于矩阵进行降维\n",
    "    参数\n",
    "        A: 给定的任意二维矩阵 list或者numpy数组形式 shape为(m,n)\n",
    "        topk: 降维的维度 (m,n) -> (m,topk)\n",
    "        \n",
    "    返回\n",
    "        降维重构后的矩阵 (m, n)\n",
    "    hint\n",
    "        这里除了降维矩阵外，另外一个较为常见的应用就是对矩阵进行重构，具体的做法类似前面的思路\n",
    "        1. 选取对应的U，D，V的topk行向量\n",
    "        2. U的按照前topk截取的行向量 * topk截取的对角矩阵 * V按照前topk截取的行向量(注意这里需要转置,因为分解得到的是V^T)\n",
    "        \n",
    "\"\"\"\n",
    "def calc_svd_reconsitution(A, topk = 2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (选做) 5.4、计算不同降维大小重构矩阵的Frobenius范数损失\n",
    "\n",
    "定义矩阵$A$以及使用SVD降维（降维大小为k)分解后的重构矩阵$A_k$，则这里的F范数损失定义如下：\n",
    "\n",
    "  $$ \\Large Loss_{F} = {\\Vert A - A_k \\Vert}_F $$\n",
    "  \n",
    "这里需要编码求出对于给定的矩阵A 分别在不同的降维幅度下重构后的F范数损失，并且作出损失大小随着降维大小的变化图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 不要修改这里！\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "A = load_boston()['data']  # 载入boston house 数据集\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "for topk in range(1,13):\n",
    "    # 5.4 TODO \n",
    "    ### 1.计算相应的SVD topk降维后的重构矩阵，需实现calc_svd_reconsitution\n",
    "    ### 2.计算对应的F范数损失，并存储loss放入loss_hist列表中\n",
    "    \n",
    "\n",
    "### 画出F损失随着降维大小的变化图\n",
    "### x坐标为对应的降维大小，y坐标为对应的F损失\n",
    "plt.plot(range(1,13),loss_hist,'r--')\n",
    "plt.xlabel('decomposition size')\n",
    "plt.ylabel('F Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5、SVD的有趣应用\n",
    "为了这个习题我准备了两张图，参见项目文件夹下的test_girl.jpg和test_boy.jpeg，自选一张，你需要\n",
    "- 需要使用 `PIL` 加载你所选择的图像（[文档](https://pillow.readthedocs.io/en/latest/reference/Image.html)）,所以记得导入需要的包（模块）\n",
    "- 使用Image的[convert方法](https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.Image.convert)将图像变为黑白色\n",
    "- 将convert后的结果转换成np.array,需用到[Image.getdata方法](https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.Image.getdata)\n",
    "- 使用上方实现的calc_svd函数赋值给变量：U,D,V\n",
    "- 打印出U,D,V的shape形状，尤其注意观察D的shape\n",
    "- 在U，V，D变量成功实现的情况下，运行测试程序看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.5 TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#请在U，D，V变量完成的情况下调用此测试程序，不要修改此处\n",
    "plt.figure(figsize=(16,6))\n",
    "for i,topk in enumerate([5, 10, 15, 20, 30, 50]):\n",
    "    reconstimg = np.matrix(U[:, :topk]) * np.diag(D[:topk]) * np.matrix(V[:topk, :])\n",
    "    plt.subplot(231+i)\n",
    "    plt.imshow(reconstimg, cmap='gray')\n",
    "    title = \"n = %s\" % i\n",
    "    plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6、 问答题：\n",
    "\n",
    "结合测试程序，单从定义角度来回答以下问题：\n",
    "\n",
    "- 为什么用np.matrix，而不用np.array?这两个区别是什么？\n",
    "- 为什么D要用np.diag?\n",
    "- 从矩阵乘法或者SVD的概念中来解释**i**为什么在U中是列，而在V中是行？\n",
    "\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda3",
   "language": "python",
   "name": "myconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
